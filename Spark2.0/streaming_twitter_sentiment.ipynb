{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.streaming import StreamingContext\n",
    "import pyspark.sql.types as tp\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoderEstimator, VectorAssembler\n",
    "from pyspark.ml.feature import StopWordsRemover, Word2Vec, RegexTokenizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing spark session\n",
    "sc = SparkContext(appName=\"spark_streaming_twitter_sentiment\")\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+--------------------+\n",
      "| id|label|               tweet|\n",
      "+---+-----+--------------------+\n",
      "|  1|    0| @user when a fat...|\n",
      "|  2|    0|@user @user thank...|\n",
      "|  3|    0|  bihday your maj...|\n",
      "|  4|    0|#model   i love u...|\n",
      "|  5|    0| factsguide: soci...|\n",
      "+---+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('twitter_sentiment.csv', header=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('id', 'string'), ('label', 'string'), ('tweet', 'string')]\n",
      "[('id', 'string'), ('label', 'int'), ('tweet', 'string')]\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)\n",
    "df = df.withColumn('label', df['label'].cast(tp.IntegerType()))\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+--------------------+\n",
      "| id|label|               tweet|\n",
      "+---+-----+--------------------+\n",
      "|  1|    0| @user when a fat...|\n",
      "|  2|    0|@user @user thank...|\n",
      "|  3|    0|  bihday your maj...|\n",
      "|  4|    0|#model   i love u...|\n",
      "|  5|    0| factsguide: soci...|\n",
      "+---+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_df = spark.read.csv('sample.csv', header=True)\n",
    "sample_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('id', 'string'), ('label', 'string'), ('tweet', 'string')]\n",
      "[('id', 'string'), ('label', 'int'), ('tweet', 'string')]\n"
     ]
    }
   ],
   "source": [
    "print(sample_df.dtypes)\n",
    "sample_df = sample_df.withColumn('label', sample_df['label'].cast(tp.IntegerType()))\n",
    "print(sample_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model Pipeline - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define stage 1: tokenize the tweet text    \n",
    "stage_1 = RegexTokenizer(inputCol= 'tweet' , outputCol= 'tokens', pattern= '\\\\W')\n",
    "\n",
    "# define stage 2: remove the stop words\n",
    "stage_2 = StopWordsRemover(inputCol= 'tokens', outputCol= 'filtered_words')\n",
    "\n",
    "# define stage 3: create a word vector of the size 200\n",
    "stage_3 = Word2Vec(inputCol= 'filtered_words', outputCol= 'vector', vectorSize= 200)\n",
    "\n",
    "# define stage 4: Logistic Regression Model\n",
    "model = LogisticRegression(featuresCol= 'vector', labelCol= 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the pipeline\n",
    "pipeline = Pipeline(stages= [stage_1, stage_2, stage_3, model])\n",
    "\n",
    "# fit the pipeline model with the training data\n",
    "pipelineFit = pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2019-12-18 23:46:27\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-12-18 23:46:30\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-12-18 23:46:33\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-12-18 23:46:36\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-12-18 23:46:39\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-12-18 23:46:42\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-12-18 23:46:45\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-12-18 23:46:48\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-12-18 23:46:51\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-12-18 23:46:54\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-12-18 23:46:57\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-12-18 23:47:00\n",
      "-------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "host = 'localhost'\n",
    "port = 9879\n",
    "\n",
    "# initialize the streaming context \n",
    "ssc = StreamingContext(sc, batchDuration=3)  # 3 sec\n",
    "\n",
    "lines = ssc.socketTextStream(host, port)\n",
    "counts = lines.flatMap(lambda line: line.split(\"TWEET APP\"))\\\n",
    "                  .map(lambda word: (word, 1))\\\n",
    "                  .reduceByKey(lambda a, b: a+b)\n",
    "counts.pprint()\n",
    "\n",
    "ssc.start() # start the computation\n",
    "ssc.awaitTermination()  # wait till finishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda3_env",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
